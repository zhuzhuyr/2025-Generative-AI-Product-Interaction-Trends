
过去一年（2024–2025），生成式 AI 从“会回答问题的工具”，跃迁为“能与人并肩工作的同事”。各类AI平台百花齐放，也引来了生成式AI平台的交互范式革新。我将从品牌视觉，交互范式与产出形态三重方向对生成式ai产品进行发展趋势分析。（包含针对范用户与专业用户的平台）

人机交互正沿着五级台阶跃迁：

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/1.png" height="450"></div>

**L1 指令步骤执行**：人发号施令、机按步就班，人的主导性明显强于机器；

**L2 预定义任务自动化**：流程被固化为模板与规则，机器在执行力与稳定性上已大于人；

**L3 开放域任务自动化**：系统具备理解目标、分解任务与自我调度的能力，机器的行为空间开始包含人类常规操作；

**L4 专家级自动化定制服务**：模型以可以根据领域知识、工具链与上下文，提供接近专家的个性化方案与交付，机器在效率与质量上远大于人；

**L5 数字分身**：个人与组织的分身可在多场景长期自治运行、持续学习并代表用户做决策，机器能力在规模、时效与适应性上远远大于人。任务完全可以托管、可追溯与可控

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/2.png" height="450"></div>

交互传递以自然的唤起进入场景；用清晰的边界限定目标、权限与数据范围；通过有效的沟通把需求结构化；在可控的生成中允许中途纠偏；生成可信的结果（可溯源、可验证）；最后把反馈沉淀为成长的模型，持续优化下一轮交互。将以此为基础框架对生成式AI平台进行分析。

一. Ai工具变为合作伙伴，身份角色与视觉形象升级
===

情感表达是拟人化的另一个重要组成部分。适度的拟人化能够建立信任，提高合作效率，除了ai语言口吻上的拟人化，交互界面中的视觉元素也成为传达情绪的途径之一。

**<ins>❓当前问题：Ai缺乏情绪化表达。当前ai品牌化logo与对话界面缺乏情绪化传递。大部分AI平台依旧采取基础UI元素与常用科技类AI配色（例如蓝紫，粉色，黄色）来构建平台视觉系统。</ins>**

**行业趋势：除完全拟人态的数字人外logo形态除了表达状态还开始传递个性，不同的状态有不同的表情传递情绪**

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/11.png" height="450"></div>

Notion 设计了一套能够个性化响应用户操作的AI 助手形象。用眼睛、眉毛和鼻子，有趣的动作，重新想象了典型的 UI 状态——思考时眉毛会眉毛像海浪一样起伏摆动，出现错误时脸部会暂时崩溃（短暂“散架”后迅速复位）等等。Notion Ai 3.0为用户提供个性化配饰装扮

二.有效的沟通：Ai输入与交互方式升级，输入范式与沟通机制重构
===

**<ins>❓问题一：用户面对输入框不知所措，“空白画布效应”</ins>**
<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/12.png" height="450"></div>
当用户面对一个只给输入框的对话界面时用户并不知道Ai能帮自己做什么。Ai的能力范围不可见、表达负担过高造成了在输入步骤时的启动困难。这时，用户会产生犹豫、试探性输入、频繁撤回与放弃（或切换至其他软件搜索如何使用）等一系列有犹豫的行为。用户难以将自己“意图”转变为“任务指令”下达给Ai。

**行业趋势：在对话框周围展示AI能力，给用户提供不同的AI模块**

**<ins>❓产生的问题：首页成为能力秀场，布局混乱。业务首页堆积了很多能力，和输入框的关键性弱，首页信息爆炸</ins>**
<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/豆包.png" height="350"></div>

解决案例：copilot
<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/13.png" height="350"></div>
365copilot将搜索类型分为“搜索类”，“对话类”，“创作类”三类。

搜索类：以事实检索与汇总为目标，联网搜索，强调来源可追溯与时效性。例如：找资料、比对文件、问“是什么/在哪里/多少/有没有更新”等。

对话类：以任务协同与推理对齐为目标，强调来回澄清、分步规划与上下文记忆。例如分析图表，对会议纪要/行动项/进行追问或梳理

创作类：以生成具体媒介为目标，例如图片，视频，音频等多模态的产出形式。强调版式/结构/语调/受众等参数化控制。

**<ins>❓问题二：用户输入自然语言表达不准确，即用户输入与Ai直接存在gap</ins>**

用户的想法并提出的问题与输入： “10月去新西兰南岛自驾怎么玩？”

用户实际意图：“我国庆从上海出发，前往新西兰旅游10天，带两位老人，预算4000一天。落地奥克兰计划南北岛都玩。希望自驾游玩，请帮我规划不走回头路的路线，并推荐沿途住宿与美食景点。”

Gap：缺少出发地、确切日期、驾驶时长偏好、预算、游玩偏好等。

用户意图存在隐喻，而ai只能听懂更加详细的分类指令。用户的意图难以精确表达，如何让用户讲出自己的需求

**行业趋势1：对prompt进行优化**

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/6.png" height="250"></div>

Anthropic 在 Claude 开发者控制台里提供一键“润色提示词”功能：用户把现有的提示词丢进去，它会自动分析并生成更稳健的模板。适合用于复杂、高准确度任务。该模块输出的结果是可直接调用的结构化提示模板。

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/%E6%88%AA%E5%B1%8F2025-10-06%2012.39.35.png" height="250"></div>

Flowith 的提示词生成模块是在把想法变成可用 Prompt的一键工具：当用户遇到表述困难时，只需要写下想要的内容。提示词优化模块就会调用模型将用户混乱的思维转变为有逻辑的，结构化的提示词模版。适合用户不会写长 Prompt 或想把临时想法快速模板化的场景。

**行业趋势2:提供提示词模版与撰写指导**

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/%E6%88%AA%E5%B1%8F2025-10-06%2013.27.54.png" height="350"></div>

Microsoft Copilot Prompt Gallery提供边看边用的“场景化范例库”。在 Copilot Chat 内可以直接打开 Gallery。按照不同任务场景，用户可以复制/改写提示词库中的案例，应用于自身的场景需求中。
 
<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/14.png" height="250"></div>

Google Prompting guide 101：提供给用户规则化、可迁移的“写作手册”。将一个任务从“模糊需求”演进到“结构化指令”的方式演示给用户，并给出不同角色/场景的示例。

通过提示词模版结构化的框架进行约束，降低用户表达模糊性。

**行业趋势3：从单一模态到多模态，输入范式不再只是单一的文字。界面即消失，环境即画布。**

Krea Ai
<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/15.png" height="350"></div>

在 Krea AI 中，输入不再只靠文字，而是画布本身+周边环境纳入输入。用户可在实时画布上用笔刷、遮罩、拖拽物体等手势直接“对素材下指令”，系统即刻回馈；同时可接入摄像头/屏幕做实时风格化与动作映射，把你的手势、光标移动、时间线拖动等“环境信号”转译为输入指令。

“输入 = 一段文本” ⏩️ “输入=文本 + 图像/视频参考 + 画布交互 + 环境传感”。 

Gemini视频通话/共享屏幕
<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/%E6%88%AA%E5%B1%8F2025-10-06%2023.39.25.png" height="350"></div>

实施读取屏幕与环境中的内容，通过多模态（文本/语音/图像/视频/实时摄像头/文件/位置）的形式了解用户意图

总结：生成式 AI 的输入正从单一文本模态的输入，转变为为多模态（文本/语音/图像/视频/实时摄像头/文件/传感器/位置/上下文数据/手绘内容）协同；同时 UI 从“显式对话框”退到后台，把用户所处的环境直接变成交互画布（文档、网页、桌面、地图、相机取景器、现实空间等）。

**<ins>❓问题三：不知道如何与ai高效沟通</ins>**

在生成式ai平台加入深入思考模式后，导致了单轮对话的时间增长（大约需要20-40分钟不等），用户输入等待时间长，中途难以更改。过程不可见，等待期缺少可视化进度与可插手节点；使得到答案后不满意的编辑成本变高。在用户提问阶段，如何与ai进行高效沟通成为问题。

**行业趋势:多轮追问，意图校准，明确用户意图。**

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/4.png" height="350"></div>
解决方案：深度思考模式下，依靠延伸追问，确认用户意图细节

三.可控的生成：Ai具备自主思考，任务分解，工具调用与多agent协同
===

**<ins>❓问题一：ai思考过程透明度不够高，等待时间太长，不知道Ai在干嘛（思考了什么，调用了什么工具？什么能力？有哪些agent可以协同,进度如何了）</ins>**
<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/%E5%AE%B9%E5%99%A8%201.png" height="350"></div>

**行业趋势：任务思考，步骤执行，工具调用透明化，增强用户掌控感**

案例：
<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/%E5%AE%B9%E5%99%A8%202.png" height="350"></div>

Manus 通过Cloud Browser，在受控的沙盒（右侧，可收起）展示ai针对任务的操作流程，实施显示所搜索的网页与步骤。

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/chatgpt.png" height="350"></div>

Chatgpt Agent通过在canves对话框内可视化操作流程让用户清晰了解AI在干嘛、下一步要干嘛、我能怎么插手。 用户可通过下方进度条定位到任意步骤查看详情。

**<ins>❓问题二.可控性差，执行中出现问题，用户无法及时介入与调整</ins>**

在用户与ai的对话中，指令发出后用户无法修改，只能根据结果完全展示后进行二次提问。若在执行中出现问题，用户无法立刻介入与调整问题。

**行业趋势：任务进行时可参展Ai的思考补全指令，提供中断或接管机制**

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/68.jpg" height="350"></div>
在 Perplexity “研究进行中”的时候，你可以直接修改提示或补充约束（如换时间范围/数据源/受众）。 Perplexity 会立刻停止当前检索流程并重规划（重新生成查询与来源队列），而不是等它把一轮跑完再返工。


**<ins>❓问题三.并发行弱，无法同时跑多个任务</ins>**

**行业趋势：多任务并行，降低执行时间，提升资源利用率**

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/%E6%88%AA%E5%B1%8F2025-10-13%2015.13.23.png" height="350"></div>

Google Project Mariner 支持用户在输入框输入的指令后，在虚拟机内的浏览器上进行多项任务并行自动化操作。

**<ins>❓问题四:不同终端自动驾驶的边界不同</ins>**

**行业趋势：探索桌面agent，调用本地app**

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/7.png" height="350"></div>
Copilot可以访问Microsoft系列中的个人/公司数据，Chatgpt可以通过连接器添加外部第三方平台，扩大工具边界。

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/IMG_8227.jpg" height="350"></div>
Raycast ，可以在电脑桌面启动工作流，让AI与电脑上所有工具直接对话。

四.可控的生成：Ai输出变成协同产物，协同canvas下的交互产物
===

**<ins>❓问题一：阅读困难（长文本堆砌、层级不清、无法快速抓要点/结构）</ins>**

“深度研究”模式下生成的长文本内容，让用户在阅读时需要花费更长的时间去重新理解。面对长文本用户无法快速得到自己想要的重点答案。

**<ins>❓问题二：编辑困难（难以对生成内容做精确、局部、可控的编辑）</ins>**

长推理模式下耗时长“中途不可更改”，没有可编辑的中间态界面。面对 o1 这类深思模型，用户很难在模型“思考中途”插入修正（比如改数据范围、替换约束），导致结束一轮对话后才发现方向错，返工成本高。

**<ins>❓问题三：查找困难 (难对比，难回溯，难定位来源)</ins>**

回溯难，版本对比难：当用户对同一问题进行修改二次提问时，得到的答案难以与历史版本进行对比查看。

对话历史里“证据链”缺失：在与ai对话的聊天中，随着时间的增加，信息来源常散落或缺失，后续很难回溯。在大多数通用聊天里，用户并不清楚“答案来自哪儿、是不是我的空间内数据”，回溯对比困难。

**<ins>❓问题四：逻辑断裂（推理过程与产出脱节、上下文跳跃）</ins>**

o1 等“深度推理”模型：过程不可见、不可插话。“深度推理”模型强调长链路推理，但默认不向用户暴露完整思考链，用户看到的是“结论+少量摘要”，中途难以对齐意图或更正前提，容易出现“最后答案看起来很整齐、但细看发现内容中提早已跑偏”的问题。

**行业趋势：Ai能力从一轮输出变成多轮协同，实时共创**

**1.有结构的生成**

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/5%20(1).png" height="350"></div>
提供结构化页面：Perplexity 阅读模式将页面结构化，把长回答拆成段落、卡片与来源，降低阅读负荷。
减少用户获取关键信息的时间，提高了AI生成内容的可读性和可理解性。

**2.分散生成到组织空间**

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/image%201.png" height="350"></div>

Claude 推出 Artifacts/Projects 让生成部分独立在右侧呈现、可编辑。

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/Canvas_Hero.webp" height="350"></div>

OpenAI 把 Canvas 定位为“更适合写作/编码的协同窗口”，因为在纯聊天里做“局部修改、版本对比、结构重排”非常痛。

Microsoft AutoGen / Agent Framework
官方框架直接支持并发代理、并行工具调用与多代理协作模式，可把同一消息分发给多个代理并行处理。
 
**3.节点式生成**

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/%E6%88%AA%E5%B1%8F2025-10-09%2000.04.37.png" height="350"></div>

Flowith采用非线性导航系统，以思维导图/大纲视图/时间轴图一键切换。模块化的容器以可伸缩的气泡/卡片形式呈现。支持拖拽语重组与潜逃层级的可视化操作。

**4.版本溯源**

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/grok.png" height="150"></div>

grok 历史版本查看

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/IMG_8229.jpg" height="250"></div>

Flowith版本沙盒，历史版本以平行时间线呈现。支持节点不同语言模型版本对比与合并。

<div align=center><img src="https://github.com/zhuzhuyr/2025-Generative-AI-Product-Interaction-Trends/blob/main/pics/curser.png" height="250"></div>
Cursor 采用高亮的形式，将对话记录中的分解步骤与具体代码对应上，绿色代表新加或延用，红色代表删除的代码。便于用户区别新旧代码
